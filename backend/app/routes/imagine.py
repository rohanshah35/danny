from fastapi import APIRouter, UploadFile, File, Form, HTTPException
from fastapi.responses import JSONResponse
import base64
from io import BytesIO
from PIL import Image
import os
from dotenv import load_dotenv

# Import the Gemini client and configuration types
from google import genai
from google.genai import types

router = APIRouter()

# Load environment variables from .env file
load_dotenv(os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), '.env'))

# Initialize the Gemini API client.
client = genai.Client(api_key=os.getenv("GEMINI_API_KEY"))

@router.post("/generate")
async def generate_design(
    image: UploadFile = File(...),
    prompt: str = Form(...)
):
    """
    Endpoint to generate a design image using the Gemini API.

    Expects:
      - image: The uploaded image file from the user.
      - prompt: A text prompt describing the desired design.

    Returns:
      - A JSON object containing the new generated image as a base64 string.
    """
    # Input validation
    if not image:
        raise HTTPException(status_code=400, detail="No image file provided.")
    if not prompt.strip():
        raise HTTPException(status_code=400, detail="Prompt text is required.")

    # Optionally read the uploaded image file.
    # In case Gemini supports conditioning on image inputs, you might modify the API call.
    try:
        image_bytes = await image.read()
        # If you need the image data to pass as extra context for Gemini,
        # you might include it in the prompt or adjust the request here.
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error reading image file: {str(e)}")
    
    try:
        # Convert the uploaded image bytes to a PIL image object
        pil_image = Image.open(BytesIO(image_bytes))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error processing the image: {str(e)}")
    

    try:
        # Call the Gemini API with the provided prompt.
        # Here, we use the prompt directly. Depending on Gemini's capabilities,
        # you might combine the image data into your contents or metadata.

        contents = [prompt, pil_image]


        response = client.models.generate_content(
            model="gemini-2.0-flash-exp-image-generation",
            contents=contents,
            config=types.GenerateContentConfig(
                response_modalities=['Text', 'Image']
            )
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error calling Gemini API: {str(e)}")

    # Process the response from Gemini.
    generated_image_base64 = None
    text_response = []
    
    try:
        # The response may contain multiple parts.
        # We iterate through the parts to capture both text and image data.
        for part in response.candidates[0].content.parts:
            if part.text is not None:
                text_response.append(part.text)
            elif part.inline_data is not None:
                # Convert the binary data into an image, then re-encode to base64.
                try:
                    image_obj = Image.open(BytesIO(part.inline_data.data))
                    buffered = BytesIO()
                    image_obj.save(buffered, format="PNG")
                    generated_image_base64 = base64.b64encode(buffered.getvalue()).decode("utf-8")
                except Exception as img_error:
                    raise HTTPException(status_code=500, detail=f"Error processing generated image: {str(img_error)}")
    except Exception as proc_error:
        raise HTTPException(status_code=500, detail=f"Error processing Gemini API response: {str(proc_error)}")

    if generated_image_base64 is None:
        raise HTTPException(status_code=500, detail="No image generated by the Gemini API.")

    # Return the generated image as a base64 string.
    return JSONResponse(content={"base64_image": generated_image_base64, "text": text_response})
